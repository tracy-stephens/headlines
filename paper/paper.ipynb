{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Detection of New York Times Articles with DBCSAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The underlying data is New York Times articles between January 2000 and June 2020 obtained through their free and public [Archive API](https://developer.nytimes.com/docs/archive-product/1/overview). To limit the scope of the analysis, I limited the articles to those with a particular keyword. For the baseline version of the model, these are only articles that contain the keyword 'Brazil'.\n",
    "\n",
    "Headlines vs. Abstracts\n",
    "The average headline is 8.7 words long, and the average abstract is 35.8 tokens words.\n",
    "\n",
    "* Show different types of keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Detection\n",
    "\n",
    "DBSCAN is commonly used in event detection because it allows for clusters of ambiguous size and number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model: GloVe\n",
    "\n",
    "For the baseline version of the model, I use pre-trained word vectors from the Global Vectors for Word Representation algorithm. These vectors were trained on data from \n",
    "\n",
    "Context-free - single word embedding representation\n",
    "https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "* just to do average for GloVe becaue it is easiest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline Embeddings\n",
    "\n",
    "In the baseline version, we take the average embedding across each headline. The has the problem that more frequent words are given as much significance as less frequent words. \n",
    "\n",
    "https://openreview.net/forum?id=SyK00v5xx\n",
    "better baseline for context-free embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "\n",
    "Evaluating performance of unsupervied algorithms is not as straightforward as it is for supervised algorithms. Previously used metrics for evaluting clustering algorithms generally fall into one of two categories: those that require an external ground-truth measure of similarity, such as class labels, and those that do not. \n",
    "\n",
    "Cluster Validity Indices\n",
    "\n",
    "This [2011 paper](https://arxiv.org/pdf/1507.03340.pdf) summarizes how these various metrics compare across different five different clustering algorithms applied to user data. The relative performance of each clustering algorithm differed substantially depending on the metric applied. In their research DBSCAN tended to appear to perform relatively better on x, x, and x, and worse on x, x, and x. This could be tied to the fact that DBSCAN clusters may be non-regular shapes and sizes and may not have a clear center.\n",
    "\n",
    "In the first category, sever\n",
    "\n",
    "### Internal Cluster Validation Metrics\n",
    "\n",
    "https://arxiv.org/pdf/1507.03340.pdf\n",
    "These techniques compare inter\n",
    "\n",
    "1. **Silhouette Index** evaluates cluster validity based on the average distances of each point. For each datapoint $i$, we compute: $$S_i = \\frac{b_i-a_i}{max(a_i, b_i)}$$ where $a_i$ is the average distance of the point to all other points in its cluster, and $b_i$ is the average distance of the point to each point outside the cluster. The final index is computed: $$C = \\frac{S-S_{min}}{S_{max} - S_{min}}$$ For any given point, $b_i-a_i$ can be negative since the DBSCAN algorithm can accommadate clusters of irregular sizes. In this case, model iterations with very low levels of epsilon resulted in negative Silhouette Indices. \n",
    "\n",
    "http://datamining.rutgers.edu/publication/internalmeasures.pdf\n",
    "2. The **Calinski Harabasz Index** compares the average sum of squares within each cluster to the average sum of squares between each cluster: $$CH=\\frac{\\frac{SSB}{k-1}}{\\frac{SSW}{N-k}}$$ where SSB is the sum of within the clusters, and SSB is the sum of squares between the clusters.\n",
    "\n",
    "Since DBSCAN does not produce convex clusters, it makes more sense to use a density-based cluster validity measure. In other words, because DBSCAN aims to achieve the highest level of intra-cluster density, rather than the highest level of closeness to a central point, cluster validity indices that account for density are more appropriate than those that only account for the intra-cluster distance between all points in a cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pdfs.semanticscholar.org/581c/71da74bd3baa06693cc6d0751e7c60f81bb3.pdf\n",
    "3. **SD** T: $SD = \\alpha Scatt + Dist$ where $Scatt = \\frac{1}{n}\\sum_{i=1}^n{\\frac{\\lVert\\sigma(v_i)\\rVert}{\\lVert\\sigma(x)\\rVert}}$ with $\\sigma(v_i)$ being the variance of cluster $i$ and $\\sigma(x)$ being the variance of the dataset.\n",
    "\n",
    "https://www.researchgate.net/publication/3940215_Clustering_Validity_Assessment_Finding_the_optimal_partitioning_of_a_data_set\n",
    "4. **S Dbw** compares cluster compactness, measured by intra-cluster variance, vs cluster separation, measured by inter-cluster density. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Cluster Validation Metrics\n",
    "\n",
    "Given that there is no available ground truth for the topic of each article, we need to identify some sort of proxy. In this paper, we'll look at two options: author and keyword. \n",
    "\n",
    "In this section, we analyze whether the model tends to cluster articles with the same author together. \n",
    "\n",
    "\n",
    "\"Keywords\"\n",
    "Keywords are given types, for example 'subject' and 'geolocation'. Now we check if  \n",
    "\n",
    "**Homogeneity Score** if all the elements within each cluster are from the same class. \n",
    "\n",
    "**Completeness Score** if all elements of each given class fall into the same cluster\n",
    "\n",
    "**Normalized Mutual Information** \n",
    "\n",
    "\n",
    "* Show a list of articles by the same author\n",
    "\n",
    "- Compare the cluster labels with the author\n",
    "- Compare the cluster labels with the other keywords\n",
    "- Compare clusters by pub_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03\n",
    "https://huggingface.co/transformers/installation.html\n",
    "https://arxiv.org/abs/1810.04805 <- white paper\n",
    "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "\n",
    "Transformers include contextual relationships. \n",
    "\n",
    "Pre-trained \n",
    "https://github.com/huggingface/transformers/issues/1950\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repostories:\n",
    "SIF - https://github.com/PrincetonML/SIF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
